{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ee6a01-85ce-4edf-8d29-a9fd5d3d0add",
   "metadata": {},
   "source": [
    "# Part 3: Understanding evaluation metrics for classification\n",
    "In this section, you will explore different metrics that can be used for classification. For this purpose, we will be studying the [Pima Indians Diabetes Dataset](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database). \n",
    "\n",
    "The goal is to train a classifier to diagnose (predict) diabetes given a set of input features.\n",
    "\n",
    "You will use the evaluation metrics you implemented to assess the quality of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd53907-737c-4d78-ad74-91c19be20ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# We will be using the metrics that you implemented in part 1\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167d713-94b7-44e2-8ffc-c6c8b7c26996",
   "metadata": {},
   "source": [
    "As before, let's load the dataset and then do some exploration of the data. You may add further analyses if you consider it necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e22c5e-6550-4b2a-baa9-71ef1446360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the dataset\n",
    "diabetes = pd.read_csv('../data/diabetes.csv', sep=\",\")\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795965f-4db9-4762-a5d3-d56e699b1598",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.hist(figsize=(12, 10), bins=30, edgecolor=\"black\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94510e-80fd-4133-8a57-fca9f4787ac8",
   "metadata": {},
   "source": [
    "**Question**: What can you say about the distribution of the different features?\n",
    "\n",
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a95d71-2bcb-49d5-bd9c-c7b7354d4e08",
   "metadata": {},
   "source": [
    "Now, let's move into training a classifier. \n",
    "\n",
    "As in part 2, we will train a single model without focusing on the task of model selection. In real-life problems, you cannot do this, as you will need to explore different options that can lead to the best model possible (the one that generalizes best).\n",
    "\n",
    "We create a function fit_and_test that will receive a training set to train a model using linear discriminant analysis (LDA) and a test set for prediction using the previously trained model. \n",
    "\n",
    "*Note:* Any other classifier could have been used. You are free to test other classifier algorithms already covered in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c4c6a-baeb-49b6-9038-eb4ad30f98cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_test(X_train, y_train, X_test):\n",
    "    #Create an LDA model\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)  \n",
    "\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_pred = model.predict(X_test) \n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97d19d-e34d-49e2-a4a1-af255753b12b",
   "metadata": {},
   "source": [
    "Now, let's train and test. As we are not going to do model selection, in this lab we will do one split of the data into training and testing. The training data will not be furthe split into train and validation. \n",
    "\n",
    "**Remember this should not be done when solving a machine learning problem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f46729-15fe-495a-9221-2f40631eff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing inputs and output into X and y\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# We call fit_and_test to first train and then infer new prices for the test set\n",
    "y_pred = fit_and_test(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838dda7-5f4c-40c1-a613-bc0825c39413",
   "metadata": {},
   "source": [
    "### How good is this model?\n",
    "\n",
    "Use the metrics that you implemented in part one to evaluate the model. Use the cell below for your experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe5883-38ee-45f5-8452-973024bb9490",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "\n",
    "#Print the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b0fbdb-61e6-4ffe-9b0d-5a997c6ff081",
   "metadata": {},
   "source": [
    "**Question:** Which metrics did you choose? Justify your answer.\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "\n",
    "**Question:** Analyze the specific values of the chosen metrics in the context of the problem to understand the model's accuracy. Is it a good or a bad model? Provide a detailed justification of your answer.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Question:** What is precision telling you about the disease? recall? and F1 score?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab59f9fe-d454-4e33-9671-de4a122dee46",
   "metadata": {},
   "source": [
    "### Imbalanced data\n",
    "Now we will repeat the exercise simulating a scenario of highly imbalanced datasets. In healthcare applications, for instance, it is common that there will be a large number of healthy cases and a few pathological ones.\n",
    "\n",
    "We will simulate this scenario by removing some rows from diabetic patients. Then, we will see how these affect the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d8365d-4ef6-45a4-9e21-63167cde74b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows with target label 1\n",
    "target_1_indices = diabetes[diabetes['Outcome'] == 1].index\n",
    "\n",
    "# Randomly select 80% of the indices\n",
    "num_to_remove = int(len(target_1_indices) * 0.8)\n",
    "indices_to_remove = np.random.choice(target_1_indices, num_to_remove, replace=False)\n",
    "\n",
    "# Remove the selected rows from the DataFrame\n",
    "diabetes = diabetes.drop(indices_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662216f-97e7-4798-8c28-08af361104f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = diabetes.drop('Outcome', axis=1)\n",
    "y = diabetes['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# We call fit_and_test to first train and then infer new prices for the test set\n",
    "y_pred = fit_and_test(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb3d0a-bf74-4afd-a4a2-d092be95d6d6",
   "metadata": {},
   "source": [
    "Use the metrics that you implemented in part one to evaluate the model. Use the cell below for your experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9156a-4b7c-4abd-a201-82bced8d5670",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "#Print the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da81e4-ae99-4231-aae5-a01505ea3a60",
   "metadata": {},
   "source": [
    "**Question:** What can you say about this model?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Question:** Which metrics provide the most useful information? Investigate and propose a solution \n",
    "\n",
    "**Answer:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
